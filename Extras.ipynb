{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook containts different model and ensemble technique that we have tried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score ,roc_curve,auc\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from collections import Counter\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import  VotingClassifier\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "pd.set_option('display.max_column',100)\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData = pd.read_csv('../input/airbnb-new-user/train.csv')\n",
    "TestData = pd.read_csv('../input/airbnb-new-user/test.csv')\n",
    "SessData = pd.read_csv('../input/airbnb-new-user/sessions.csv')\n",
    "SessData.rename(columns={'user_id':'id'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_type = pd.pivot_table(SessData, index = ['id'],columns = ['action_type'],values = 'secs_elapsed',aggfunc=len,fill_value=0).reset_index()\n",
    "action = pd.pivot_table(SessData, index = ['id'],columns = ['action'],values = 'secs_elapsed',aggfunc=len,fill_value=0).reset_index()\n",
    "action_detail = pd.pivot_table(SessData, index = ['id'],columns = ['action_detail'],values = 'secs_elapsed',aggfunc=len,fill_value=0).reset_index()\n",
    "device_type = pd.pivot_table(SessData, index = ['id'],columns = ['device_type'],values = 'secs_elapsed',aggfunc=len,fill_value=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataCom = pd.concat((TrainData.drop('country_destination',axis=1),TestData),axis=0,ignore_index=True)\n",
    "def set_age_group(x):\n",
    "    if x < 40:\n",
    "        return 'Young'\n",
    "    elif x >=40 and x < 60:\n",
    "        return 'Middle'\n",
    "    elif x >= 60 and x <= 125:\n",
    "        return 'Old'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "\n",
    "def set_age(x):\n",
    "    if x>=16 and x<=120:\n",
    "        return x\n",
    "    elif x<16:\n",
    "        return np.nan\n",
    "    elif x>120:\n",
    "        if 2015-x>16 and 2015-x<110:\n",
    "            return 2015-x\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "def set_categorial_values(x):\n",
    "    l = ['first_browser','affiliate_provider','first_device_type','affiliate_channel','first_affiliate_tracked','signup_app']\n",
    "    thresold = [0.00]*10\n",
    "    \n",
    "    i = l.index(x)\n",
    "    l1 = DataCom[x].value_counts(normalize=True)\n",
    "    l2 = l1[l1>thresold[i]].index.tolist()\n",
    "    return DataCom[x].apply(lambda x: x if x in l2 else 'diff')\n",
    "\n",
    "def feature_engineering(df):\n",
    "    df['DAC_year'] = np.vstack(df['date_account_created'].astype(str).apply(lambda x: list(map(int, x.split('-')))).values)[:,0]\n",
    "    df['DAC_month'] = np.vstack(df['date_account_created'].astype(str).apply(lambda x: list(map(int, x.split('-')))).values)[:,1]\n",
    "    df['DAC_day'] = np.vstack(df['date_account_created'].astype(str).apply(lambda x: list(map(int, x.split('-')))).values)[:,2]\n",
    "    df['DAC_dayofweek'] = pd.to_datetime(df['date_account_created']).dt.dayofweek\n",
    "    \n",
    "    df['TFA_year'] = np.vstack(df.timestamp_first_active.astype(str).apply(lambda x: list(map(int, [x[:4],x[4:6],x[6:8],x[8:10],x[10:12],x[12:14]]))).values)[:,0]\n",
    "    df['TFA_month'] = np.vstack(df.timestamp_first_active.astype(str).apply(lambda x: list(map(int, [x[:4],x[4:6],x[6:8],x[8:10],x[10:12],x[12:14]]))).values)[:,1]\n",
    "    df['TFA_day'] = np.vstack(df.timestamp_first_active.astype(str).apply(lambda x: list(map(int, [x[:4],x[4:6],x[6:8],x[8:10],x[10:12],x[12:14]]))).values)[:,2]\n",
    "    df['TFA_hour'] = np.vstack(df.timestamp_first_active.astype(str).apply(lambda x: list(map(int, [x[:4],x[4:6],x[6:8],x[8:10],x[10:12],x[12:14]]))).values)[:,3]\n",
    "    \n",
    "    df['DFB_year'] = np.vstack(df['date_first_booking'].fillna(-1).astype(str).apply(lambda x: -1 if x=='-1' else list(map(int,x.split('-')))[0] ))\n",
    "    df['DFB_month'] = np.vstack(df['date_first_booking'].fillna(-1).astype(str).apply(lambda x: -1 if x=='-1' else list(map(int,x.split('-')))[1] ))\n",
    "    df['DFB_day'] = np.vstack(df['date_first_booking'].fillna(-1).astype(str).apply(lambda x: -1 if x=='-1' else list(map(int,x.split('-')))[2] ))\n",
    "    df['DFB_dayofweek'] = pd.to_datetime(df['date_first_booking']).dt.dayofweek\n",
    "    \n",
    "    df['lag'] = (pd.to_datetime(df.date_account_created)-pd.to_datetime(df.timestamp_first_active,format='%Y%m%d%H%M%S')).dt.days\n",
    "    \n",
    "    df['age'] = df['age'].apply(set_age)\n",
    "    df['age_group'] = df['age'].apply(set_age_group)\n",
    "    df['age'] = df['age'].fillna(-1)\n",
    "    \n",
    "    \n",
    "    df['has_booked'] = df['date_first_booking'].fillna(-1).apply(lambda x: 0 if x==-1 else 1)\n",
    "    df['first_affiliate_tracked'] = df['first_affiliate_tracked'].fillna('unknown')\n",
    "    \n",
    "    l = ['first_browser','affiliate_provider','first_device_type','affiliate_channel','first_affiliate_tracked','signup_app']\n",
    "    for x in l:\n",
    "        df[x] = set_categorial_values(x)\n",
    "            \n",
    "    ohe = ['gender', 'signup_method', 'language', 'affiliate_channel', 'affiliate_provider', \n",
    "           'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser','age_group']\n",
    "    \n",
    "    for x in ohe:\n",
    "        combined_data,_ = pd.factorize(df[x],sort=True)\n",
    "        combined_data = pd.Series(combined_data).astype('int32')\n",
    "        df[x] = combined_data.values  \n",
    "    \n",
    "    droplist = ['date_account_created','timestamp_first_active','date_first_booking','signup_method']\n",
    "    df = df.drop(droplist,axis=1)\n",
    "    \n",
    "    df = pd.merge(df, action_type[['id','booking_response','-unknown-']], how='left', on='id')\n",
    "    df = pd.merge(df, action[['id','requested', 'confirm_email', 'update', 'cancellation_policies']], how='left', on='id')\n",
    "    df = pd.merge(df, action_detail[['id','pending', 'at_checkpoint']], how='left', on='id')\n",
    "    \n",
    "    df = df.set_index('id')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "DataCom = feature_engineering(DataCom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = TrainData['country_destination']             \n",
    "labels = y.values\n",
    "le = LabelEncoder()\n",
    "y = pd.Series(le.fit_transform(labels))      \n",
    "\n",
    "X = DataCom[:TrainData.shape[0]]                        # encoded train data x               \n",
    "df_test = DataCom[TrainData.shape[0]:]                  # encoded test data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y,random_state=31, train_size=0.80,  stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8738391912542612\n"
     ]
    }
   ],
   "source": [
    "xgb3 = xgb.XGBClassifier(max_depth=4, learning_rate=0.01, n_estimators=75,\n",
    "                    objective='multi:softprob', subsample=0.6, colsample_bytree=0.6, seed=40,reg_lambda=0.5)\n",
    "xgb3.fit(X, y)\n",
    "print(xgb3.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.4002534\ttest: 2.4002566\tbest: 2.4002566 (0)\ttotal: 430ms\tremaining: 21.1s\n",
      "1:\tlearn: 2.3246206\ttest: 2.3246177\tbest: 2.3246177 (1)\ttotal: 884ms\tremaining: 21.2s\n",
      "2:\tlearn: 2.2560967\ttest: 2.2560883\tbest: 2.2560883 (2)\ttotal: 1.27s\tremaining: 19.9s\n",
      "3:\tlearn: 2.1935011\ttest: 2.1934946\tbest: 2.1934946 (3)\ttotal: 1.6s\tremaining: 18.4s\n",
      "4:\tlearn: 2.1361821\ttest: 2.1361654\tbest: 2.1361654 (4)\ttotal: 2.04s\tremaining: 18.4s\n",
      "5:\tlearn: 2.0829798\ttest: 2.0829698\tbest: 2.0829698 (5)\ttotal: 2.48s\tremaining: 18.2s\n",
      "6:\tlearn: 2.0334779\ttest: 2.0334691\tbest: 2.0334691 (6)\ttotal: 2.8s\tremaining: 17.2s\n",
      "7:\tlearn: 1.9872891\ttest: 1.9872821\tbest: 1.9872821 (7)\ttotal: 3.25s\tremaining: 17.1s\n",
      "8:\tlearn: 1.9440081\ttest: 1.9440038\tbest: 1.9440038 (8)\ttotal: 3.7s\tremaining: 16.8s\n",
      "9:\tlearn: 1.9033506\ttest: 1.9033355\tbest: 1.9033355 (9)\ttotal: 4.15s\tremaining: 16.6s\n",
      "10:\tlearn: 1.8648835\ttest: 1.8648658\tbest: 1.8648658 (10)\ttotal: 4.53s\tremaining: 16.1s\n",
      "11:\tlearn: 1.8285131\ttest: 1.8284930\tbest: 1.8284930 (11)\ttotal: 4.99s\tremaining: 15.8s\n",
      "12:\tlearn: 1.7940079\ttest: 1.7939863\tbest: 1.7939863 (12)\ttotal: 5.44s\tremaining: 15.5s\n",
      "13:\tlearn: 1.7612934\ttest: 1.7612713\tbest: 1.7612713 (13)\ttotal: 5.88s\tremaining: 15.1s\n",
      "14:\tlearn: 1.7301031\ttest: 1.7300803\tbest: 1.7300803 (14)\ttotal: 6.41s\tremaining: 15s\n",
      "15:\tlearn: 1.7002993\ttest: 1.7002736\tbest: 1.7002736 (15)\ttotal: 6.79s\tremaining: 14.4s\n",
      "16:\tlearn: 1.6717901\ttest: 1.6717641\tbest: 1.6717641 (16)\ttotal: 7s\tremaining: 13.6s\n",
      "17:\tlearn: 1.6445637\ttest: 1.6445380\tbest: 1.6445380 (17)\ttotal: 7.45s\tremaining: 13.2s\n",
      "18:\tlearn: 1.6184307\ttest: 1.6184078\tbest: 1.6184078 (18)\ttotal: 7.9s\tremaining: 12.9s\n",
      "19:\tlearn: 1.5933434\ttest: 1.5933190\tbest: 1.5933190 (19)\ttotal: 8.34s\tremaining: 12.5s\n",
      "20:\tlearn: 1.5692387\ttest: 1.5692136\tbest: 1.5692136 (20)\ttotal: 8.79s\tremaining: 12.1s\n",
      "21:\tlearn: 1.5460474\ttest: 1.5460219\tbest: 1.5460219 (21)\ttotal: 9.24s\tremaining: 11.8s\n",
      "22:\tlearn: 1.5237440\ttest: 1.5237180\tbest: 1.5237180 (22)\ttotal: 9.69s\tremaining: 11.4s\n",
      "23:\tlearn: 1.5022529\ttest: 1.5022263\tbest: 1.5022263 (23)\ttotal: 10.1s\tremaining: 11s\n",
      "24:\tlearn: 1.4814795\ttest: 1.4814505\tbest: 1.4814505 (24)\ttotal: 10.6s\tremaining: 10.6s\n",
      "25:\tlearn: 1.4614330\ttest: 1.4614011\tbest: 1.4614011 (25)\ttotal: 11s\tremaining: 10.2s\n",
      "26:\tlearn: 1.4420644\ttest: 1.4420328\tbest: 1.4420328 (26)\ttotal: 11.5s\tremaining: 9.76s\n",
      "27:\tlearn: 1.4233123\ttest: 1.4232813\tbest: 1.4232813 (27)\ttotal: 11.9s\tremaining: 9.36s\n",
      "28:\tlearn: 1.4051412\ttest: 1.4051103\tbest: 1.4051103 (28)\ttotal: 12.4s\tremaining: 8.95s\n",
      "29:\tlearn: 1.3875358\ttest: 1.3875046\tbest: 1.3875046 (29)\ttotal: 12.6s\tremaining: 8.37s\n",
      "30:\tlearn: 1.3704757\ttest: 1.3704438\tbest: 1.3704438 (30)\ttotal: 12.9s\tremaining: 7.89s\n",
      "31:\tlearn: 1.3539477\ttest: 1.3539197\tbest: 1.3539197 (31)\ttotal: 13.3s\tremaining: 7.5s\n",
      "32:\tlearn: 1.3378849\ttest: 1.3378555\tbest: 1.3378555 (32)\ttotal: 13.7s\tremaining: 7.07s\n",
      "33:\tlearn: 1.3222899\ttest: 1.3222652\tbest: 1.3222652 (33)\ttotal: 14.2s\tremaining: 6.66s\n",
      "34:\tlearn: 1.3071377\ttest: 1.3071127\tbest: 1.3071127 (34)\ttotal: 14.4s\tremaining: 6.16s\n",
      "35:\tlearn: 1.2924329\ttest: 1.2924104\tbest: 1.2924104 (35)\ttotal: 14.8s\tremaining: 5.76s\n",
      "36:\tlearn: 1.2781046\ttest: 1.2780818\tbest: 1.2780818 (36)\ttotal: 15.3s\tremaining: 5.37s\n",
      "37:\tlearn: 1.2641695\ttest: 1.2641460\tbest: 1.2641460 (37)\ttotal: 15.5s\tremaining: 4.91s\n",
      "38:\tlearn: 1.2506144\ttest: 1.2505890\tbest: 1.2505890 (38)\ttotal: 16s\tremaining: 4.51s\n",
      "39:\tlearn: 1.2374112\ttest: 1.2373876\tbest: 1.2373876 (39)\ttotal: 16.4s\tremaining: 4.11s\n",
      "40:\tlearn: 1.2245355\ttest: 1.2245117\tbest: 1.2245117 (40)\ttotal: 16.9s\tremaining: 3.71s\n",
      "41:\tlearn: 1.2119973\ttest: 1.2119703\tbest: 1.2119703 (41)\ttotal: 17.4s\tremaining: 3.31s\n",
      "42:\tlearn: 1.1997694\ttest: 1.1997420\tbest: 1.1997420 (42)\ttotal: 17.6s\tremaining: 2.87s\n",
      "43:\tlearn: 1.1878561\ttest: 1.1878295\tbest: 1.1878295 (43)\ttotal: 18.1s\tremaining: 2.46s\n",
      "44:\tlearn: 1.1762184\ttest: 1.1761960\tbest: 1.1761960 (44)\ttotal: 18.5s\tremaining: 2.06s\n",
      "45:\tlearn: 1.1648626\ttest: 1.1648392\tbest: 1.1648392 (45)\ttotal: 19s\tremaining: 1.65s\n",
      "46:\tlearn: 1.1537732\ttest: 1.1537505\tbest: 1.1537505 (46)\ttotal: 19.4s\tremaining: 1.24s\n",
      "47:\tlearn: 1.1429522\ttest: 1.1429299\tbest: 1.1429299 (47)\ttotal: 19.9s\tremaining: 830ms\n",
      "48:\tlearn: 1.1323735\ttest: 1.1323520\tbest: 1.1323520 (48)\ttotal: 20.4s\tremaining: 416ms\n",
      "49:\tlearn: 1.1220447\ttest: 1.1220194\tbest: 1.1220194 (49)\ttotal: 20.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.122019428\n",
      "bestIteration = 49\n",
      "\n",
      "0.8738391912542612\n"
     ]
    }
   ],
   "source": [
    "cat1 = CatBoostClassifier(iterations=50,learning_rate = 0.01)\n",
    "cat1.fit(X,y,eval_set=(x_test, y_test))\n",
    "print(cat1.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8858587045962149"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbmodel1 = LGBMClassifier(learning_rate=0.1,n_estimators=300)\n",
    "lgbmodel1.fit(X,y)\n",
    "lgbmodel1.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.5756437\ttotal: 322ms\tremaining: 1.29s\n",
      "1:\tlearn: 0.5074613\ttotal: 764ms\tremaining: 1.15s\n",
      "2:\tlearn: 0.4980512\ttotal: 1.22s\tremaining: 810ms\n",
      "3:\tlearn: 0.4926831\ttotal: 1.75s\tremaining: 437ms\n",
      "4:\tlearn: 0.4890949\ttotal: 2.42s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.5745474\ttotal: 301ms\tremaining: 1.2s\n",
      "1:\tlearn: 0.5057818\ttotal: 687ms\tremaining: 1.03s\n",
      "2:\tlearn: 0.4964825\ttotal: 1.05s\tremaining: 704ms\n",
      "3:\tlearn: 0.4907251\ttotal: 1.5s\tremaining: 376ms\n",
      "4:\tlearn: 0.4873036\ttotal: 1.92s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.5755796\ttotal: 316ms\tremaining: 1.26s\n",
      "1:\tlearn: 0.5073235\ttotal: 726ms\tremaining: 1.09s\n",
      "2:\tlearn: 0.4941844\ttotal: 1.18s\tremaining: 785ms\n",
      "3:\tlearn: 0.4889438\ttotal: 1.6s\tremaining: 399ms\n",
      "4:\tlearn: 0.4857008\ttotal: 2s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.5756204\ttotal: 274ms\tremaining: 1.1s\n",
      "1:\tlearn: 0.5108733\ttotal: 729ms\tremaining: 1.09s\n",
      "2:\tlearn: 0.4920953\ttotal: 1.14s\tremaining: 761ms\n",
      "3:\tlearn: 0.4826833\ttotal: 1.52s\tremaining: 381ms\n",
      "4:\tlearn: 0.4778768\ttotal: 1.9s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.5756218\ttotal: 251ms\tremaining: 1s\n",
      "1:\tlearn: 0.5058915\ttotal: 620ms\tremaining: 930ms\n",
      "2:\tlearn: 0.4917034\ttotal: 994ms\tremaining: 663ms\n",
      "3:\tlearn: 0.4835474\ttotal: 1.35s\tremaining: 339ms\n",
      "4:\tlearn: 0.4800980\ttotal: 1.73s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.5724508\ttotal: 364ms\tremaining: 1.46s\n",
      "1:\tlearn: 0.5059297\ttotal: 715ms\tremaining: 1.07s\n",
      "2:\tlearn: 0.4961051\ttotal: 1.06s\tremaining: 705ms\n",
      "3:\tlearn: 0.4906651\ttotal: 1.41s\tremaining: 352ms\n",
      "4:\tlearn: 0.4873607\ttotal: 1.76s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8738391912542612"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack = StackingClassifier(estimators=[('xgb',xgb3),('cat',CatBoostClassifier(iterations=5))], final_estimator=LogisticRegression(),cv=5)\n",
    "stack.fit(X,y)\n",
    "stack.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.5756437\ttotal: 419ms\tremaining: 1.68s\n",
      "1:\tlearn: 0.5074613\ttotal: 1.06s\tremaining: 1.59s\n",
      "2:\tlearn: 0.4980512\ttotal: 1.61s\tremaining: 1.07s\n",
      "3:\tlearn: 0.4926831\ttotal: 2.11s\tremaining: 527ms\n",
      "4:\tlearn: 0.4890949\ttotal: 2.58s\tremaining: 0us\n",
      "0.8738391912542612\n"
     ]
    }
   ],
   "source": [
    "max_vot = VotingClassifier(estimators=[('xgb', xgb3), ('cat', CatBoostClassifier(iterations=5))],voting='soft')\n",
    "max_vot.fit(X,y)\n",
    "print(max_vot.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = xgb3.predict_proba(df_test)\n",
    "id_test = TestData['id']\n",
    "\n",
    "id_final_sub = []  \n",
    "pred_final_sub = [] \n",
    "for i in range(len(id_test)):\n",
    "    idx = id_test[i]\n",
    "    id_final_sub += [idx] * 3\n",
    "    pred_final_sub += le.inverse_transform(np.argsort(prob[i])[::-1])[:3].tolist()\n",
    "\n",
    "sub = pd.DataFrame(np.column_stack((id_final_sub,pred_final_sub)), columns=['id', 'country_destination'])\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
